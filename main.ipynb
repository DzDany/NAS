{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8de1016",
   "metadata": {},
   "source": [
    "### Partes de un tensor\n",
    "\n",
    "La ventaja que tiene sobre NumPy es que es acelerado por GPU y **autograd**.\n",
    "\n",
    "Los tensores de imágenes se leen así: (C, H, W)\n",
    "\n",
    "C: Número de canales.\n",
    "\n",
    "H: Altura de la imagen.\n",
    "\n",
    "W: Anchura de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "671f1f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets \n",
    "from torchvision.transforms import ToTensor # Convierte una imagen a tensor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "371aef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu126\n",
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f695c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data y test_data son objetos de Dataset\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor() # Se aplica a cada imagen cuando se accede, no a todas de una\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b612678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d355c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 6742, 7: 6265, 3: 6131, 2: 5958, 9: 5949, 0: 5923, 6: 5918, 8: 5851, 4: 5842, 5: 5421})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter # Estructura de datos para contar frecuencias de elementos\n",
    "\n",
    "labels = [training_data[i][1] for i in range(len(training_data))]\n",
    "counts = Counter(labels)\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e35056",
   "metadata": {},
   "source": [
    "DataLoader: es un iterador inteligente de PyTorch. Toma un Dataset y lo convierte en lotes (batches) \n",
    "\n",
    "iter(train_loader): convierte el DataLoader en un iterador. Es como decir for batch in train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4948063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# DATALOADER \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64 # Cuántos ejemplos se procesan juntos en una sola pasada por el modelo\n",
    "                # El modelo \"ve\" 64 imágenes al mismo tiempo\n",
    "                \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True # Mezcla los datos en cada época\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False # Para que los resultados sean reproducibles\n",
    ")\n",
    "\n",
    "X, y = next(iter(train_loader)) \n",
    "print(X.shape) # (64, 1, 28, 28) \n",
    "print(y.shape) # (64,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931be18",
   "metadata": {},
   "source": [
    "### Capas\n",
    "\n",
    "#### Capa de escaneo\n",
    "\n",
    "nn.Conv2d: Define capas de escaneo para imágenes. Pieza fundamental de las CNN. Su trabajo es detectar patrones (bordes, texturas o formas) deslizando un kernel sobre la imagen. Si detecta algo envía una señal fuerte. El resultado es una nueva \"imagen\" (mapa de características) donde se resaltan los patrones encontrados.\n",
    "\n",
    "Primeros dos argumentos: input channels (cuántos canales tiene la imagen de entrada) y output channels/filters (cuántos filtros se aplicarán, por ende, cuántos mapas de características se obtendrán).\n",
    "\n",
    "#### Capa de reducción\n",
    "\n",
    "Hace la imagen más pequeña para que la red sea más rápida y se enfoque solo en lo más importante. Max pooling es una técnica que divide la imagen en una cuadrícula de pequeños cuadros y mira cada cuadro y se queda solo con el número más grande, descartando los demás. Se reduce el tamaño y evita el ruido.\n",
    "\n",
    "Parámetros: tamaño cuadrado del kernel y cuánto se \"salta\" la ventana cada vez que se mueve.\n",
    "\n",
    "#### Capas densas o lineales\n",
    "\n",
    "Capa donde todas las neuronas de la entrada se conectan con todas las neuronas de la salida. A diferencia de las convolucionales, estas miran toda la información junta para clasificarla. \n",
    "\n",
    "Parámetros: entrada y salida (10 neuronas para 10 dígitos). \n",
    "\n",
    "### Otros aspectos\n",
    "\n",
    "x.view(x.size(0), -1) \n",
    "\n",
    "x.view() es la función que cambia la forma (dimensión) de un tensor sin mover sus datos en la memoria. Como reshape en NumPy\n",
    "\n",
    "- x.size(0) mantiene el tamaño del batch\n",
    "\n",
    "- -1 estira todos los píxeles de los 32 mapas de 7x7 en una sola fila larga.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c28aa810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # Define piezas estructurales de la red que tienen parámetros entrenables (pesos y sesgos)\n",
    "import torch.nn.functional as F # Aplica funciones sobre los datos que no tienen parámetros propios. Son acciones matemáticas que no necesitan recordad nada de la iteración anterior\n",
    "\n",
    "class SimpleCNN(nn.Module): # nn.Module es la madre de todas las redes\n",
    "    def __init__(self):\n",
    "        super().__init__() # Conecta la clase con todas las funciones internas de PyTorch\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    # Define el camino que siguen los datos desde que entran hasta que se obtiene un resultado\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Capas de extracción (Convolución + Activación + Pooling)\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (N,16,14,14)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (N,32,7,7)\n",
    "        \n",
    "        # Aplanado o flatten\n",
    "        x = x.view(x.size(0), -1)   \n",
    "        \n",
    "        # Capas de decisión (fully connected)           \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fe7001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Componentes que hacen que la red aprenda\n",
    "criterion = nn.CrossEntropyLoss() # Se define la función de pérdida y mide qué tan mal lo está haciendo la red\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # Define la optimización, encargado de ajustar los pesos para no cometer el mismo error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X = X.to(device) # Mueve los datos a la GPU\n",
    "        y = y.to(device)\n",
    "\n",
    "        # BACKPROPAGATION\n",
    "        optimizer.zero_grad() # Borra los gradientes\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward() # Viaja hasta la primera capa y calcula cuánta responsabilidad tuvo cada peso en el error final\n",
    "        optimizer.step() # Cambia ligeramente los pesos de las neuronas para minimizar el error\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35138d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(): # with es un manejador de contexto. Específicamente aquí dice que durante este bloque que aplique esta configuración especial (no calcular gradientes)\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            outputs = model(X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0432dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.2299, acc=0.9756\n",
      "Epoch 2: loss=0.0645, acc=0.9845\n",
      "Epoch 3: loss=0.0435, acc=0.9845\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    acc = evaluate(model, test_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: loss={loss:.4f}, acc={acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d080390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ola'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Robot:\n",
    "    def __init__(self, nombre):\n",
    "        self.nombre = nombre\n",
    "        \n",
    "    def saludar(self):\n",
    "        print(f\"Hola, soy {self.nombre}\")\n",
    "        \n",
    "    def dinero(self, din):\n",
    "        self.din = din\n",
    "        \n",
    "    def cant(self):\n",
    "        print(self.din)\n",
    "        \n",
    "rob = Robot(\"ola\")\n",
    "rob.nombre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24301c85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a58d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Convertimos a tensores\n",
    "predicciones = torch.tensor([1, 2, 1, 1, 40])\n",
    "etiquetas    = torch.tensor([1, 1, 1, 1, 40])\n",
    "\n",
    "# 2. Comparamos (esto crea [True, False, True, True, False])\n",
    "comparacion = (predicciones == etiquetas)\n",
    "\n",
    "# 3. Sumamos los True\n",
    "aciertos = comparacion.sum()\n",
    "\n",
    "print(aciertos.item())\n",
    "\n",
    "print(len(y)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
